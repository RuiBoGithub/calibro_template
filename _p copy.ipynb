{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier = 'bD_Z2_S2'\n",
    "identifier_specify = identifier[-5:]\n",
    "tex = f\"{identifier}/output/calibro_report.tex\"\n",
    "_idfPath = f\"../eplus_diagnosis/idf-Oct/G2/auto-cal/bD_alpha_{identifier_specify}.idf\"\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from _approach_a import *\n",
    "here = Path.cwd()\n",
    "src_dir = next(p for p in [here, *here.parents] if (p / \"src\").exists()) / \"src\"\n",
    "sys.path.insert(0, str(src_dir))\n",
    "from ReIDF import ReIDF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_office_string(pattern, ending=';'):\n",
    "    result = []\n",
    "    for value, count in pattern:\n",
    "        result.extend([value] * count)\n",
    "    return ', '.join(result) + ending\n",
    "\n",
    "# Defaults (model's baseline values if no calibrated value exists)\n",
    "d1_htgsp_office_default = 18\n",
    "d2_htgsp_office_st_default = 15\n",
    "\n",
    "# Placeholder schedules (raw form prior to replacement)\n",
    "d1_htg_updated_weekday = generate_office_string([\n",
    "    ('15', 8), ('{{d1_htgsp_office}}', 11), ('15', 5)\n",
    "])\n",
    "\n",
    "d2_htg_updated_weekend = generate_office_string([('{{d2_htgsp_office_st}}', 24)])\n",
    "\n",
    "d2_htg_updated_weekday = generate_office_string([\n",
    "    ('{{d2_htgsp_office_st}}', 8), ('{{d1_htgsp_office}}', 11), ('{{d2_htgsp_office_st}}', 5)\n",
    "])\n",
    "\n",
    "# Original user-defined lists (must preserve format)\n",
    "ReUnit_HVAC = [\n",
    "    ('MaterialExt_W', 3, '{{a1_u_value_external_walls}}'),\n",
    "    ('MaterialExt_Win', 2, '{{a3_u_value_external_windows}}'),\n",
    "    ('MaterialExt_Win 1', 2, '{{a3_u_value_external_windows}}'),\n",
    "    ('MaterialExt_Win 2', 2, '{{a3_u_value_external_windows}}'),\n",
    "    ('MaterialExt_Win', 3, '{{a4_g_value}}'),\n",
    "    ('MaterialExt_Win 1', 3, '{{a4_g_value}}'),\n",
    "    ('MaterialExt_Win 2', 3, '{{a4_g_value}}'),\n",
    "    ('htg_sch_office_br__Weekday', 3, d1_htg_updated_weekday),\n",
    "    ('htg_sch_office_br__Weekday', 3, d2_htg_updated_weekday),\n",
    "    ('htg_sch_office_br__Sunday', 3, d2_htg_updated_weekend),\n",
    "]\n",
    "\n",
    "ReClass_HVAC = [\n",
    "    ('ZoneVentilation:WindandStackOpenArea', 3, '{{e1_natural_ventilation_rate}}'),\n",
    "    ('ZoneVentilation:WindandStackOpenArea', 7, '{{e1_natural_ventilation_rate}}'),\n",
    "    ('ZoneInfiltration:DesignFlowRate', 7, '{{a5_infiltration_rate}}'),\n",
    "    ('Fan:ConstantVolume', 3, '{{b1_ahu_fan_efficiency}}'),\n",
    "    ('AirLoopHVAC', 11, '{{b10_airloophvac}};'),\n",
    "    ('SetpointManager:OutdoorAirReset', 3, '{{b12_sat}}'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('ZoneVentilation:WindandStackOpenArea', 3, '1.223'),\n",
       "  ('ZoneVentilation:WindandStackOpenArea', 7, '1.223'),\n",
       "  ('ZoneInfiltration:DesignFlowRate', 7, '0.872'),\n",
       "  ('SetpointManager:OutdoorAirReset', 3, '23.360')],\n",
       " [('htg_sch_office_br__Weekday',\n",
       "   3,\n",
       "   '15, 15, 15, 15, 15, 15, 15, 15, 23.779, 23.779, 23.779, 23.779, 23.779, 23.779, 23.779, 23.779, 23.779, 23.779, 23.779, 15, 15, 15, 15, 15;'),\n",
       "  ('htg_sch_office_br__Weekday',\n",
       "   3,\n",
       "   '17.775, 17.775, 17.775, 17.775, 17.775, 17.775, 17.775, 17.775, 23.779, 23.779, 23.779, 23.779, 23.779, 23.779, 23.779, 23.779, 23.779, 23.779, 23.779, 17.775, 17.775, 17.775, 17.775, 17.775;'),\n",
       "  ('htg_sch_office_br__Sunday',\n",
       "   3,\n",
       "   '17.775, 17.775, 17.775, 17.775, 17.775, 17.775, 17.775, 17.775, 17.775, 17.775, 17.775, 17.775, 17.775, 17.775, 17.775, 17.775, 17.775, 17.775, 17.775, 17.775, 17.775, 17.775, 17.775, 17.775;')])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, param_map, ReUnit_CalibroMID, ReClass_CalibroMID = process_all(\n",
    "    tex,\n",
    "    ReUnit_HVAC,\n",
    "    ReClass_HVAC,\n",
    "    drop_missing=True \n",
    ")\n",
    "ReClass_CalibroMID, ReUnit_CalibroMID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ZoneVentilation:WindandStackOpenArea', 3, '1.223'),\n",
       " ('ZoneVentilation:WindandStackOpenArea', 7, '1.223'),\n",
       " ('ZoneInfiltration:DesignFlowRate', 7, '0.872'),\n",
       " ('SetpointManager:OutdoorAirReset', 3, '23.360')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ReClass_CalibroMID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReIDF: → /Users/rui.bo/Desktop/Working/1-phd_mainworks/Y3/eplus_diagnosis/idf-Oct/G2/post-cal/POSTbD_alpha_Z2_S2.idf\n",
      "ReUnit: [{'htg_sch_office_br__Weekday': 1}, {'htg_sch_office_br__Weekday': 1}, {'htg_sch_office_br__Sunday': 1}]\n",
      "ReClass: [{'ZoneVentilation:WindandStackOpenArea': 15}, {'ZoneVentilation:WindandStackOpenArea': 15}, {'ZoneInfiltration:DesignFlowRate': 14}, {'SetpointManager:OutdoorAirReset': 1}]\n"
     ]
    }
   ],
   "source": [
    "_idfPath = Path(_idfPath)\n",
    "updated = ReIDF1(oriPath=_idfPath, \n",
    "                 ReClass=ReClass_CalibroMID, \n",
    "                 ReUnit=ReUnit_CalibroMID, \n",
    "                 cusPath=_idfPath.parent / \"..\" / \"post-cal\" / ( 'POST' + _idfPath.stem + _idfPath.suffix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PARAMETER</th>\n",
       "      <th>ESTIMATE</th>\n",
       "      <th>LOWER</th>\n",
       "      <th>UPPER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e1_natural_ventilation_rate</td>\n",
       "      <td>1.296</td>\n",
       "      <td>0.860</td>\n",
       "      <td>1.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b10_airloophvac</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.644</td>\n",
       "      <td>1.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b12_sat</td>\n",
       "      <td>22.903</td>\n",
       "      <td>17.028</td>\n",
       "      <td>26.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d2_htgsp_office_st</td>\n",
       "      <td>15.969</td>\n",
       "      <td>15.047</td>\n",
       "      <td>17.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d1_htgsp_office</td>\n",
       "      <td>23.692</td>\n",
       "      <td>21.187</td>\n",
       "      <td>23.972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     PARAMETER ESTIMATE   LOWER   UPPER\n",
       "0  e1_natural_ventilation_rate    1.296   0.860   1.345\n",
       "1              b10_airloophvac    0.770   0.644   1.026\n",
       "2                      b12_sat   22.903  17.028  26.015\n",
       "3           d2_htgsp_office_st   15.969  15.047  17.851\n",
       "4              d1_htgsp_office   23.692  21.187  23.972"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, param_map, ReUnit_PLACEHOLDER, ReClass_PLACEHOLDER = process_all(\n",
    "    tex,\n",
    "    ReUnit_HVAC,\n",
    "    ReClass_HVAC,\n",
    "    drop_missing=True,\n",
    "    overwrite_with_derived=False  # Keep original placeholders but drop unresolved ones\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from pyDOE2 import lhs\n",
    "from SALib.sample.morris import sample as morris_sample\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# =============================================================\n",
    "# 0. DISTRIBUTION INFERENCE FROM df (LaTeX TABLE)\n",
    "# =============================================================\n",
    "\n",
    "# df is expected to contain columns: PARAMETER, ESTIMATE, LOWER, UPPER\n",
    "\n",
    "\n",
    "def normalize_bound(b):\n",
    "    \"\"\"Convert 'NA' / None / numeric to a clean Python bound (or None).\"\"\"\n",
    "    if b is None:\n",
    "        return None\n",
    "    if isinstance(b, str) and b.upper() == \"NA\":\n",
    "        return None\n",
    "    return float(b)\n",
    "\n",
    "\n",
    "def detect_truncation(mu, low, up, param_name, user_bounds=None, eps=1e-6):\n",
    "    \"\"\"Decide if a parameter should be treated as truncated.\n",
    "\n",
    "    Priority:\n",
    "    1) user_bounds (if provided)\n",
    "    2) automatic detection (touching 0 or 1)\n",
    "    3) None (no truncation)\n",
    "    \"\"\"\n",
    "    # 1. User-specified bounds\n",
    "    if user_bounds is not None and param_name in user_bounds:\n",
    "        lo, hi = user_bounds[param_name]\n",
    "        lo = normalize_bound(lo)\n",
    "        hi = normalize_bound(hi)\n",
    "        if lo is not None or hi is not None:\n",
    "            return (lo, hi)\n",
    "\n",
    "    # 2. Automatic detection\n",
    "    if abs(up - 1.0) < eps:\n",
    "        return (0.0, 1.0)\n",
    "    if abs(low - 0.0) < eps:\n",
    "        return (0.0, None)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def compute_sigma_from_CI(mu, low, up):\n",
    "    \"\"\"Approximate sigma from a symmetric 95% CI, using the larger side.\"\"\"\n",
    "    dev = max(mu - low, up - mu)\n",
    "    return dev / 1.96\n",
    "\n",
    "\n",
    "def classify_with_truncation(mu, low, up, param_name, user_bounds=None):\n",
    "    \"\"\"Return (family, bounds) where family in {Normal, Lognormal, TruncatedNormal}.\"\"\"\n",
    "    trunc = detect_truncation(mu, low, up, param_name, user_bounds=user_bounds)\n",
    "    if trunc is not None:\n",
    "        return \"TruncatedNormal\", trunc\n",
    "\n",
    "    # Normal vs Lognormal by asymmetry\n",
    "    d_low = (mu - low) / mu\n",
    "    d_up = (up - mu) / mu\n",
    "\n",
    "    # avoid division by 0\n",
    "    asym_ratio = abs(d_up - d_low) / max(d_low, d_up, 1e-9)\n",
    "\n",
    "    if asym_ratio < 0.25:\n",
    "        return \"Normal\", None\n",
    "    else:\n",
    "        return \"Lognormal\", None\n",
    "\n",
    "\n",
    "def infer_distributions_with_trunc(df, user_bounds=None):\n",
    "    \"\"\"Infer distribution family + parameters for each row of df.\"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        param = row[\"PARAMETER\"]\n",
    "        mu = float(row[\"ESTIMATE\"])\n",
    "        low = float(row[\"LOWER\"])\n",
    "        up = float(row[\"UPPER\"])\n",
    "\n",
    "        family, bounds = classify_with_truncation(mu, low, up, param_name=param, user_bounds=user_bounds)\n",
    "\n",
    "        sigma = compute_sigma_from_CI(mu, low, up)\n",
    "        cv = sigma / mu if mu != 0 else np.nan\n",
    "\n",
    "        if family == \"Normal\":\n",
    "            rows.append({\n",
    "                \"Parameter\": param,\n",
    "                \"Distribution\": \"Normal\",\n",
    "                \"Mean\": mu,\n",
    "                \"Sigma\": sigma,\n",
    "                \"CV\": cv,\n",
    "                \"Lower\": np.nan,\n",
    "                \"Upper\": np.nan,\n",
    "            })\n",
    "\n",
    "        elif family == \"Lognormal\":\n",
    "            sigma_ln2 = np.log(1 + cv ** 2)\n",
    "            sigma_ln = np.sqrt(sigma_ln2)\n",
    "            mu_ln = np.log(mu) - 0.5 * sigma_ln2\n",
    "            rows.append({\n",
    "                \"Parameter\": param,\n",
    "                \"Distribution\": \"Lognormal\",\n",
    "                \"Mean\": mu,\n",
    "                \"Mu_log\": mu_ln,\n",
    "                \"Sigma_log\": sigma_ln,\n",
    "                \"CV\": cv,\n",
    "                \"Lower\": np.nan,\n",
    "                \"Upper\": np.nan,\n",
    "            })\n",
    "\n",
    "        elif family == \"TruncatedNormal\":\n",
    "            lo, hi = bounds\n",
    "            rows.append({\n",
    "                \"Parameter\": param,\n",
    "                \"Distribution\": \"TruncatedNormal\",\n",
    "                \"Mean\": mu,\n",
    "                \"Sigma\": sigma,\n",
    "                \"CV\": cv,\n",
    "                \"Lower\": lo,\n",
    "                \"Upper\": hi,\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# 1. CONVERT INFERRED DIST TABLE → parameter_specs + variable_names\n",
    "# =============================================================\n",
    "\n",
    "# We keep the structure of your previous workflow as much as possible.\n",
    "# parameter_specs will now support: normal, lognormal, truncated_normal.\n",
    "\n",
    "\n",
    "def convert_inferred_to_specs(dist_df):\n",
    "    \"\"\"Convert dist_df (from infer_distributions_with_trunc) into\n",
    "    parameter_specs and variable_names for sampling.\n",
    "    \"\"\"\n",
    "    parameter_specs = []\n",
    "    variable_names = []\n",
    "\n",
    "    for _, row in dist_df.iterrows():\n",
    "        name = row[\"Parameter\"]\n",
    "        dist = row[\"Distribution\"].lower()\n",
    "        variable_names.append(name)\n",
    "\n",
    "        if dist == \"normal\":\n",
    "            parameter_specs.append({\n",
    "                \"distribution\": \"normal\",\n",
    "                \"mean\": float(row[\"Mean\"]),\n",
    "                \"std\": float(row[\"Sigma\"]),\n",
    "            })\n",
    "\n",
    "        elif dist == \"lognormal\":\n",
    "            parameter_specs.append({\n",
    "                \"distribution\": \"lognormal\",\n",
    "                \"mu_log\": float(row[\"Mu_log\"]),\n",
    "                \"sigma_log\": float(row[\"Sigma_log\"]),\n",
    "            })\n",
    "\n",
    "        elif dist == \"truncatednormal\":\n",
    "            parameter_specs.append({\n",
    "                \"distribution\": \"truncated_normal\",\n",
    "                \"mean\": float(row[\"Mean\"]),\n",
    "                \"std\": float(row[\"Sigma\"]),\n",
    "                \"lower\": normalize_bound(row[\"Lower\"]),\n",
    "                \"upper\": normalize_bound(row[\"Upper\"]),\n",
    "            })\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported inferred distribution: {row['Distribution']}\")\n",
    "\n",
    "    return parameter_specs, variable_names\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# 2. LHS + MORRIS SAMPLING (EXTENDED TO HANDLE NEW DISTRIBUTIONS)\n",
    "# =============================================================\n",
    "\n",
    "\n",
    "def generate_samples(method, num_samples, parameter_specs, random_seed=None, N=10, num_levels=10):\n",
    "    if method == 'lhs':\n",
    "        return generate_lhs_samples_mixed(num_samples, parameter_specs, random_seed)\n",
    "    elif method == 'morris':\n",
    "        return generate_morris_samples(num_samples, parameter_specs, N, num_levels)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method. Use lhs or morris.\")\n",
    "\n",
    "\n",
    "def generate_lhs_samples_mixed(num_samples, parameter_specs, random_seed=None):\n",
    "    \"\"\"LHS sampling for a mixture of normal, lognormal, truncated_normal and uniform.\n",
    "\n",
    "    This keeps your previous structure but extends the mapping.\n",
    "    \"\"\"\n",
    "    if random_seed is not None:\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    num_parameters = len(parameter_specs)\n",
    "    lhs_samples = lhs(num_parameters, samples=num_samples)\n",
    "\n",
    "    for i, spec in enumerate(parameter_specs):\n",
    "        dist = spec['distribution']\n",
    "\n",
    "        if dist == 'uniform':\n",
    "            min_val, max_val = spec['range']\n",
    "            lhs_samples[:, i] = np.round(min_val + lhs_samples[:, i] * (max_val - min_val), 6)\n",
    "\n",
    "        elif dist == 'normal':\n",
    "            mean, std = spec['mean'], spec['std']\n",
    "            lhs_samples[:, i] = np.round(norm.ppf(lhs_samples[:, i], loc=mean, scale=std), 6)\n",
    "\n",
    "        elif dist == 'lognormal':\n",
    "            mu_log, sigma_log = spec['mu_log'], spec['sigma_log']\n",
    "            lhs_samples[:, i] = np.round(\n",
    "                np.exp(norm.ppf(lhs_samples[:, i], loc=mu_log, scale=sigma_log)), 6\n",
    "            )\n",
    "\n",
    "        elif dist == 'truncated_normal':\n",
    "            mean, std = spec['mean'], spec['std']\n",
    "            lower = spec.get('lower', None)\n",
    "            upper = spec.get('upper', None)\n",
    "\n",
    "            a = -np.inf if lower is None else (lower - mean) / std\n",
    "            b = np.inf if upper is None else (upper - mean) / std\n",
    "\n",
    "            Fa = norm.cdf(a)\n",
    "            Fb = norm.cdf(b)\n",
    "            u = lhs_samples[:, i]\n",
    "            u_trunc = Fa + u * (Fb - Fa)\n",
    "            lhs_samples[:, i] = np.round(norm.ppf(u_trunc, loc=mean, scale=std), 6)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported distribution in parameter_specs: {dist}\")\n",
    "\n",
    "    return np.nan_to_num(lhs_samples)\n",
    "\n",
    "\n",
    "def generate_morris_samples(num_samples, parameter_specs, N=10, num_levels=10):\n",
    "    \"\"\"Morris sampling (still supports uniform + normal as before).\n",
    "\n",
    "    For lognormal / truncated_normal you can either:\n",
    "    - map through an underlying normal space, or\n",
    "    - restrict Morris usage to parameters declared uniform/normal.\n",
    "\n",
    "    Here we keep it simple and *only* support uniform + normal\n",
    "    (lognormal / truncated_normal would raise a clear error).\n",
    "    \"\"\"\n",
    "    num_parameters = len(parameter_specs)\n",
    "\n",
    "    problem_definition = {\n",
    "        'num_vars': num_parameters,\n",
    "        'names': [f'param_{i}' for i in range(num_parameters)],\n",
    "        'bounds': [[0, 1] for _ in range(num_parameters)]\n",
    "    }\n",
    "\n",
    "    morris_samples = morris_sample(problem=problem_definition, N=N, num_levels=num_levels)\n",
    "\n",
    "    for i, spec in enumerate(parameter_specs):\n",
    "        dist = spec['distribution']\n",
    "        if dist == 'uniform':\n",
    "            min_val, max_val = spec['range']\n",
    "            morris_samples[:, i] = np.round(min_val + morris_samples[:, i] * (max_val - min_val), 6)\n",
    "        elif dist == 'normal':\n",
    "            mean = spec['mean']\n",
    "            std = spec['std']\n",
    "            p = 0.1 + 0.8 * morris_samples[:, i]\n",
    "            morris_samples[:, i] = np.round(norm.ppf(p, loc=mean, scale=std), 6)\n",
    "        else:\n",
    "            raise ValueError(f\"Morris currently supports only uniform/normal, got {dist} for index {i}\")\n",
    "\n",
    "    return morris_samples\n",
    "\n",
    "\n",
    "def visualize_lhs_samples(lhs_samples, variable_names):\n",
    "    lhs_df = pd.DataFrame(lhs_samples, columns=variable_names)\n",
    "    sns.pairplot(lhs_df)\n",
    "    plt.suptitle('Scatter Plots of LHS Samples', y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# 3. IDF CREATION (UNCHANGED, REUSABLE)\n",
    "# =============================================================\n",
    "\n",
    "\n",
    "def create_idf_files(template_file_name, cPath, variable_names, values,\n",
    "                     schedules, output_name_template, overwrite=False):\n",
    "    if not overwrite:\n",
    "        print(\"Overwrite disabled. Skipping IDF creation.\")\n",
    "        return []\n",
    "\n",
    "    cPath = Path(cPath)\n",
    "    cPath.mkdir(exist_ok=True)\n",
    "\n",
    "    template_text = Path(template_file_name).read_text()\n",
    "    file_paths = []\n",
    "\n",
    "    for i, value_set in enumerate(values, start=0):\n",
    "        f_out = template_text\n",
    "\n",
    "        if i == 0:\n",
    "            print(\"Processing 1st file ...\")\n",
    "\n",
    "        # Replace parameters: here we assume placeholders are {{ParameterName}}\n",
    "        for var, val in zip(variable_names, value_set):\n",
    "            placeholder = f\"{{{{{var}}}}}\"\n",
    "            if placeholder in f_out:\n",
    "                f_out = f_out.replace(placeholder, str(val))\n",
    "\n",
    "        # Replace schedules (if provided)\n",
    "        for schedule_name, schedule_list in (schedules or {}).items():\n",
    "            placeholder = f\"{{{{{schedule_name}_schedule}}}}\"\n",
    "            if placeholder in f_out:\n",
    "                schedule_string = \", \".join(f\"{v:.2f}\" for v in schedule_list[i]) + \";\"\n",
    "                f_out = f_out.replace(placeholder, schedule_string)\n",
    "\n",
    "        out_name = output_name_template.format(number=f\"{i:04d}\")\n",
    "        out_file = cPath / f\"{out_name}.idf\"\n",
    "        out_file.write_text(f_out)\n",
    "        file_paths.append(out_file)\n",
    "\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# 4. MAIN ENTRY (NO EXCEL, DIRECTLY FROM df + user_bounds)\n",
    "# =============================================================\n",
    "\n",
    "\n",
    "def main_from_latex_df(\n",
    "    df,\n",
    "    user_bounds,\n",
    "    template_file_name,\n",
    "    method='lhs',\n",
    "    num_samples=10,\n",
    "    overwrite=False,\n",
    "    plot_lhs=False,\n",
    "    output_name=None,\n",
    "    schedules=None,\n",
    "):\n",
    "    \"\"\"Unified workflow:\n",
    "\n",
    "    1) infer distributions (Normal / Lognormal / TruncatedNormal) from df\n",
    "    2) convert to parameter_specs + variable_names\n",
    "    3) generate LHS / Morris samples\n",
    "    4) create IDF files using {{Parameter}} placeholders\n",
    "\n",
    "    No Excel / extra CSV is required.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Infer distributions\n",
    "    dist_df = infer_distributions_with_trunc(df, user_bounds=user_bounds)\n",
    "    print(\"==== Inferred distributions ====\")\n",
    "    print(dist_df)\n",
    "\n",
    "    # 2) Convert to sampling specs\n",
    "    parameter_specs, variable_names = convert_inferred_to_specs(dist_df)\n",
    "\n",
    "    # 3) Generate samples\n",
    "    samples = generate_samples(method, num_samples, parameter_specs)\n",
    "\n",
    "    if plot_lhs and method == 'lhs':\n",
    "        visualize_lhs_samples(samples, variable_names)\n",
    "\n",
    "    # 4) Output folder: based on template location + output_name\n",
    "    template_dir = Path(template_file_name).parent.resolve()\n",
    "\n",
    "    if output_name is not None:\n",
    "        calibration_group = template_dir / output_name\n",
    "    else:\n",
    "        calibration_group = template_dir / \"samples_from_latex\"\n",
    "\n",
    "    calibration_group.mkdir(exist_ok=True)\n",
    "\n",
    "    # 5) Create IDFs\n",
    "    output_name_template = \"sample_{number}\"\n",
    "    idf_paths = create_idf_files(\n",
    "        template_file_name,\n",
    "        calibration_group,\n",
    "        variable_names,\n",
    "        samples,\n",
    "        schedules,\n",
    "        output_name_template,\n",
    "        overwrite,\n",
    "    )\n",
    "\n",
    "    # 6) Return samples and folder; no CSV autosave\n",
    "    sample_df = pd.DataFrame(samples, columns=variable_names)\n",
    "    return sample_df, calibration_group, dist_df\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# 5. EXAMPLE USAGE (SKETCH)\n",
    "# =============================================================\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_bounds = {\n",
    "    'b10_airloophvac': (None, 1),   # upper bound manually set to 1\n",
    "    'a5_infiltration_rate': (0, None),  # force lower bound at 0\n",
    "}\n",
    "\n",
    "template_file_name = \"idf-Oct/G2/auto-cal/1bD_alpha_Z2_S2.idf\"\n",
    "output_name = \"bD_Z2_S2_UQ\"\n",
    "\n",
    "sample_df, calibration_group, dist_df = main_from_latex_df(\n",
    "    df=df,\n",
    "    user_bounds=user_bounds,\n",
    "    template_file_name=template_file_name,\n",
    "    method='lhs',\n",
    "    num_samples=10,\n",
    "    overwrite=True,\n",
    "    plot_lhs=True,\n",
    "    output_name=output_name,\n",
    "    schedules=None,\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_df.to_csv(calibration_group / \"samples.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Normalise bounds\n",
    "# -------------------------------------------------------------\n",
    "def normalize_bound(b):\n",
    "    if b is None:\n",
    "        return None\n",
    "    if isinstance(b, str) and b.upper() == \"NA\":\n",
    "        return None\n",
    "    return float(b)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Detect truncation (priority: user > automatic > none)\n",
    "# -------------------------------------------------------------\n",
    "def detect_truncation(mu, low, up, param_name, user_bounds=None, eps=1e-6):\n",
    "    \n",
    "    # 1. Use user-specified bounds if provided\n",
    "    if user_bounds is not None and param_name in user_bounds:\n",
    "        lo, hi = user_bounds[param_name]\n",
    "        lo = normalize_bound(lo)\n",
    "        hi = normalize_bound(hi)\n",
    "        # If either bound is defined → truncated\n",
    "        if lo is not None or hi is not None:\n",
    "            return (lo if lo is not None else 0,\n",
    "                    hi if hi is not None else None)\n",
    "\n",
    "    # 2. Automatic detection\n",
    "    if abs(up - 1.0) < eps:\n",
    "        return (0, 1)\n",
    "    if abs(low - 0.0) < eps:\n",
    "        return (0, None)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Supporting computation\n",
    "# -------------------------------------------------------------\n",
    "def compute_sigma_from_CI(mu, low, up):\n",
    "    dev = max(mu - low, up - mu)\n",
    "    return dev / 1.96\n",
    "\n",
    "def compute_beta_params(mu, var):\n",
    "    m = mu\n",
    "    v = var\n",
    "    common = m*(1-m)/v - 1\n",
    "    alpha = m * common\n",
    "    beta  = (1-m) * common\n",
    "    return alpha, beta\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Classification: Truncated / Normal / Lognormal\n",
    "# -------------------------------------------------------------\n",
    "def classify_with_truncation(mu, low, up, param_name, user_bounds=None):\n",
    "\n",
    "    # 1. Check truncation\n",
    "    trunc = detect_truncation(mu, low, up, param_name, user_bounds=user_bounds)\n",
    "    if trunc is not None:\n",
    "        return \"TruncatedNormal\", trunc\n",
    "\n",
    "    # 2. Symmetry check (Normal vs Lognormal)\n",
    "    d_low = (mu - low) / mu\n",
    "    d_up  = (up - mu) / mu\n",
    "    asym_ratio = abs(d_up - d_low) / max(d_low, d_up, 1e-9)\n",
    "\n",
    "    if asym_ratio < 0.25:\n",
    "        return \"Normal\", None\n",
    "    else:\n",
    "        return \"Lognormal\", None\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# MAIN FUNCTION WITH ARGUMENT\n",
    "# -------------------------------------------------------------\n",
    "def infer_distributions_with_trunc(df, user_bounds=None):\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        param = row[\"PARAMETER\"]\n",
    "        mu = float(row[\"ESTIMATE\"])\n",
    "        low = float(row[\"LOWER\"])\n",
    "        up  = float(row[\"UPPER\"])\n",
    "\n",
    "        family, bounds = classify_with_truncation(mu, low, up, param_name=param, user_bounds=user_bounds)\n",
    "\n",
    "        sigma = compute_sigma_from_CI(mu, low, up)\n",
    "        cv = sigma / mu\n",
    "\n",
    "        if family == \"Normal\":\n",
    "            rows.append({\n",
    "                \"Parameter\": param,\n",
    "                \"Distribution\": \"Normal\",\n",
    "                \"Mean\": mu,\n",
    "                \"Sigma\": sigma,\n",
    "                \"CV\": cv\n",
    "            })\n",
    "\n",
    "        elif family == \"Lognormal\":\n",
    "            sigma_ln2 = np.log(1 + cv**2)\n",
    "            sigma_ln = np.sqrt(sigma_ln2)\n",
    "            mu_ln = np.log(mu) - 0.5*sigma_ln2\n",
    "\n",
    "            rows.append({\n",
    "                \"Parameter\": param,\n",
    "                \"Distribution\": \"Lognormal\",\n",
    "                \"Mean\": mu,\n",
    "                \"Mu_log\": mu_ln,\n",
    "                \"Sigma_log\": sigma_ln,\n",
    "                \"CV\": cv\n",
    "            })\n",
    "\n",
    "        elif family == \"TruncatedNormal\":\n",
    "            lo, hi = bounds\n",
    "            rows.append({\n",
    "                \"Parameter\": param,\n",
    "                \"Distribution\": \"TruncatedNormal\",\n",
    "                \"Mean\": mu,\n",
    "                \"Sigma\": sigma,\n",
    "                \"CV\": cv,\n",
    "                \"Lower\": lo,\n",
    "                \"Upper\": hi\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "user_bounds = {\n",
    "    'b10_airloophvac': (None, 1),            # upper bound manually set to 1\n",
    "    'a5_infiltration_rate': (0, None),        # force lower bound at 0\n",
    "}\n",
    "\n",
    "dist_df = infer_distributions_with_trunc(df, user_bounds=user_bounds)\n",
    "print(dist_df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eplus_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
